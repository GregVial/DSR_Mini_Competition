{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/unimelb_training.csv\")\n",
    "data.set_index(\"Grant.Application.ID\",drop=True,inplace=True)\n",
    "data.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.ix[:,:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Sponsor.Code</th>\n",
       "      <th>Grant.Category.Code</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>Start.date</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>...</th>\n",
       "      <th>SEO.Code.1</th>\n",
       "      <th>SEO.Percentage.1</th>\n",
       "      <th>SEO.Code.2</th>\n",
       "      <th>SEO.Percentage.2</th>\n",
       "      <th>SEO.Code.3</th>\n",
       "      <th>SEO.Percentage.3</th>\n",
       "      <th>SEO.Code.4</th>\n",
       "      <th>SEO.Percentage.4</th>\n",
       "      <th>SEO.Code.5</th>\n",
       "      <th>SEO.Percentage.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>8/11/05</td>\n",
       "      <td>280199.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>700299.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2B</td>\n",
       "      <td>10A</td>\n",
       "      <td>B</td>\n",
       "      <td>11/11/05</td>\n",
       "      <td>280103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280106.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280203.0</td>\n",
       "      <td>...</td>\n",
       "      <td>700103.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>700102.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grant.Status Sponsor.Code Grant.Category.Code  \\\n",
       "1             1          NaN                 NaN   \n",
       "2             1           2B                 10A   \n",
       "\n",
       "  Contract.Value.Band...see.note.A Start.date  RFCD.Code.1  RFCD.Percentage.1  \\\n",
       "1                               A     8/11/05     280199.0              100.0   \n",
       "2                               B    11/11/05     280103.0               30.0   \n",
       "\n",
       "   RFCD.Code.2  RFCD.Percentage.2  RFCD.Code.3        ...         SEO.Code.1  \\\n",
       "1          0.0                0.0          0.0        ...           700299.0   \n",
       "2     280106.0               30.0     280203.0        ...           700103.0   \n",
       "\n",
       "   SEO.Percentage.1  SEO.Code.2  SEO.Percentage.2  SEO.Code.3  \\\n",
       "1             100.0         0.0               0.0         0.0   \n",
       "2              50.0    700102.0              50.0         0.0   \n",
       "\n",
       "   SEO.Percentage.3  SEO.Code.4  SEO.Percentage.4  SEO.Code.5  \\\n",
       "1               0.0         0.0               0.0         0.0   \n",
       "2               0.0         0.0               0.0         0.0   \n",
       "\n",
       "   SEO.Percentage.5  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill missing Contract.Value.Band\n",
    "data['Contract.Value.Band...see.note.A'].fillna(value=\"A\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummies for Sponsor.Code\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Sponsor.Code\"],prefix=\"Sponsor\",dummy_na=dummy)],axis=1)\n",
    "data.drop(\"Sponsor.Code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummies for Grant.Category.Code\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Grant.Category.Code\"],prefix=\"Cat\",dummy_na=dummy)],axis=1)\n",
    "data.drop(\"Grant.Category.Code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>RFCD.Percentage.3</th>\n",
       "      <th>RFCD.Code.4</th>\n",
       "      <th>RFCD.Percentage.4</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_23.0</th>\n",
       "      <th>Day_24.0</th>\n",
       "      <th>Day_25.0</th>\n",
       "      <th>Day_26.0</th>\n",
       "      <th>Day_27.0</th>\n",
       "      <th>Day_28.0</th>\n",
       "      <th>Day_29.0</th>\n",
       "      <th>Day_30.0</th>\n",
       "      <th>Day_31.0</th>\n",
       "      <th>Day_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>280199.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>280103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280106.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280203.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>321004.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>321216.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>270602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>260500.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grant.Status Contract.Value.Band...see.note.A  RFCD.Code.1  \\\n",
       "1             1                               A      280199.0   \n",
       "2             1                               B      280103.0   \n",
       "3             1                               A      321004.0   \n",
       "4             1                               C      270602.0   \n",
       "5             0                               A      260500.0   \n",
       "\n",
       "   RFCD.Percentage.1  RFCD.Code.2  RFCD.Percentage.2  RFCD.Code.3  \\\n",
       "1              100.0          0.0                0.0          0.0   \n",
       "2               30.0     280106.0               30.0     280203.0   \n",
       "3               60.0     321216.0               40.0          0.0   \n",
       "4               50.0     320602.0               50.0          0.0   \n",
       "5               34.0     280000.0               33.0     290000.0   \n",
       "\n",
       "   RFCD.Percentage.3  RFCD.Code.4  RFCD.Percentage.4   ...     Day_23.0  \\\n",
       "1                0.0          0.0                0.0   ...            0   \n",
       "2               40.0          0.0                0.0   ...            0   \n",
       "3                0.0          0.0                0.0   ...            0   \n",
       "4                0.0          0.0                0.0   ...            0   \n",
       "5               33.0          0.0                0.0   ...            0   \n",
       "\n",
       "   Day_24.0  Day_25.0  Day_26.0  Day_27.0  Day_28.0  Day_29.0  Day_30.0  \\\n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "5         0         0         0         0         0         0         0   \n",
       "\n",
       "   Day_31.0  Day_nan  \n",
       "1         0        0  \n",
       "2         0        0  \n",
       "3         0        0  \n",
       "4         0        0  \n",
       "5         0        0  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with date\n",
    "\n",
    "a = pd.to_datetime(data[\"Start.date\"])\n",
    "year = pd.Series([date.year for date in a],name=\"year\")\n",
    "month = pd.Series([date.month for date in a],name=\"month\")\n",
    "day = pd.Series([date.day for date in a],name=\"day\")\n",
    "data[\"Start.year\"] = year\n",
    "data[\"Start.month\"] = month\n",
    "data[\"Start.day\"] = day\n",
    "\n",
    "# one hot encoding\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Start.year\"],prefix=\"Year\",dummy_na=dummy)],axis=1)\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Start.month\"],prefix=\"Month\",dummy_na=dummy)],axis=1)\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Start.day\"],prefix=\"Day\",dummy_na=dummy)],axis=1)\n",
    "\n",
    "data.drop([\"Start.date\"],axis=1,inplace=True)\n",
    "data.drop([\"Start.year\"],axis=1,inplace=True)\n",
    "data.drop([\"Start.month\"],axis=1,inplace=True)\n",
    "data.drop([\"Start.day\"],axis=1,inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummies for Contract.Val\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Contract.Value.Band...see.note.A\"],prefix=\"Contract\")],axis=1)\n",
    "data.drop(\"Contract.Value.Band...see.note.A\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummies for RFCD\n",
    "sub1 = pd.DataFrame(data.ix[:,1:3])\n",
    "sub1.rename(columns={\"RFCD.Code.1\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.1\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub2 = pd.DataFrame(data.ix[:,3:5])\n",
    "sub2.rename(columns={\"RFCD.Code.2\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.2\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub3 = pd.DataFrame(data.ix[:,5:7])\n",
    "sub3.rename(columns={\"RFCD.Code.3\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.3\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub4 = pd.DataFrame(data.ix[:,7:9])\n",
    "sub4.rename(columns={\"RFCD.Code.4\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.4\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub5 = pd.DataFrame(data.ix[:,9:11])\n",
    "sub5.rename(columns={\"RFCD.Code.5\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.5\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "RFCD = sub1.append(sub2,ignore_index=False)\n",
    "RFCD = RFCD.append(sub3,ignore_index=False)\n",
    "RFCD = RFCD.append(sub4,ignore_index=False)\n",
    "RFCD = RFCD.append(sub4,ignore_index=False)\n",
    "\n",
    "RFCD[RFCD[\"RFCD.Code\"].isnull()]=0\n",
    "\n",
    "piv = pd.pivot_table(RFCD,columns=\"RFCD.Code\",index=RFCD.index,fill_value=0,dropna=False)\n",
    "piv[piv.isnull()]=0\n",
    "piv.index.name=None\n",
    "\n",
    "#data = pd.concat([data,piv],axis=1)\n",
    "data.drop([\"RFCD.Code.1\",\"RFCD.Percentage.1\",\n",
    "           \"RFCD.Code.2\",\"RFCD.Percentage.2\",\n",
    "           \"RFCD.Code.3\",\"RFCD.Percentage.3\",\n",
    "           \"RFCD.Code.4\",\"RFCD.Percentage.4\",\n",
    "           \"RFCD.Code.5\",\"RFCD.Percentage.5\",],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummies for SEO\n",
    "sub1 = pd.DataFrame(data.ix[:,1:3])\n",
    "sub1.rename(columns={\"SEO.Code.1\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.1\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub2 = pd.DataFrame(data.ix[:,3:5])\n",
    "sub2.rename(columns={\"SEO.Code.2\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.2\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub3 = pd.DataFrame(data.ix[:,5:7])\n",
    "sub3.rename(columns={\"SEO.Code.3\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.3\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub4 = pd.DataFrame(data.ix[:,7:9])\n",
    "sub4.rename(columns={\"SEO.Code.4\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.4\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub5 = pd.DataFrame(data.ix[:,9:11])\n",
    "sub5.rename(columns={\"SEO.Code.5\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.5\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "SEO = sub1.append(sub2,ignore_index=False)\n",
    "SEO = SEO.append(sub3,ignore_index=False)\n",
    "SEO = SEO.append(sub4,ignore_index=False)\n",
    "SEO = SEO.append(sub4,ignore_index=False)\n",
    "\n",
    "SEO[SEO[\"SEO.Code\"].isnull()]=0\n",
    "\n",
    "piv = pd.pivot_table(SEO,columns=\"SEO.Code\",index=RFCD.index,fill_value=0,dropna=False)\n",
    "piv[piv.isnull()]=0\n",
    "piv.index.name=None\n",
    "\n",
    "#data = pd.concat([data,piv],axis=1)\n",
    "data.drop([\"SEO.Code.1\",\"SEO.Percentage.1\",\n",
    "           \"SEO.Code.2\",\"SEO.Percentage.2\",\n",
    "           \"SEO.Code.3\",\"SEO.Percentage.3\",\n",
    "           \"SEO.Code.4\",\"SEO.Percentage.4\",\n",
    "           \"SEO.Code.5\",\"SEO.Percentage.5\",],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:112: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "raw = pd.read_csv(\"data/unimelb_training.csv\")\n",
    "\n",
    "people = pd.DataFrame()\n",
    "time_at_uni = pd.DataFrame()\n",
    "for col in raw.columns:\n",
    "    col_list = list(raw.columns) # list so I can use index later\n",
    "\n",
    "    if col[:10] == 'Person.ID.':\n",
    "        col_start = col_list.index(col)\n",
    "        col_end = col_start + 15 # hard coded\n",
    "        person = raw.iloc[:,col_start:col_end]\n",
    "        \n",
    "       \n",
    "        # including our ID and status\n",
    "        person.loc[:,'Grant.Application.ID'] = raw.loc[:,'Grant.Application.ID']\n",
    "        person.loc[:,'Grant.Status'] = raw.loc[:,'Grant.Status']\n",
    "\n",
    "        col_names = list(person.columns)\n",
    "        col_names = [col.strip('0123456789') for col in col_names] # removes all numbers\n",
    "        person.columns = col_names\n",
    "        #print(len(person))\n",
    "        \n",
    "        # Dealing with missing IDs\n",
    "        id_ = person.loc[:,\"Person.ID.\"]\n",
    "        id_missing = [np.isnan(i) for i in id_]\n",
    "        #print(id_missing[50:60])\n",
    "        role = person.loc[:,\"Role.\"]\n",
    "        #print(role[50:60])\n",
    "        role_not_missing = [not pd.isnull(r) for r in role]\n",
    "        #print(role_not_missing[50:60])\n",
    "        no_id = [(i&r) for (i,r) in zip(id_missing,role_not_missing)]\n",
    "        #print(no_id[50:60])\n",
    "        person.loc[:,\"Person.ID.\"] = np.where(no_id,0,person.loc[:,\"Person.ID.\"])\n",
    "        #print(person.loc[50:60,\"Person.ID.\"])\n",
    "\n",
    "        # dealing with number of years at uni\n",
    "        original = person.loc[:,'No..of.Years.in.Uni.at.Time.of.Grant.'].astype(str)\n",
    "        transformed = [0 for _ in range(original.size)]\n",
    "        transformed = np.where(original==\">=0 to 5\",2.5,transformed)\n",
    "        transformed = np.where(original==\">5 to 10\",7.5,transformed)\n",
    "        transformed = np.where(original==\">10 to 15\",12.5,transformed)\n",
    "        transformed = np.where(original==\"more than 15\",20,transformed)\n",
    "        transformed = pd.DataFrame(transformed)\n",
    "\n",
    "        person[\"No..of.Years.in.Uni.at.Time.of.Grant.\"] = transformed\n",
    "        #person = pd.concat([person, transformed], axis=1)\n",
    "        people = people.append(person, ignore_index=True)\n",
    "        #print(people.loc[:,\"Person.ID.\"])\n",
    "\n",
    "# summaries for team\n",
    "#num_ppl = len(people) / len(person) # should be 15!\n",
    "people.index = people.loc[:,'Grant.Application.ID']\n",
    "num_ppl = pd.Series(people.groupby(['Grant.Application.ID'])['Person.ID.'].count(),name=\"Person.ID.\") # include\n",
    "#num_ppl = np.where(num_ppl==0,1,num_ppl)\n",
    "#print(num_ppl)\n",
    "\n",
    "num_birth_years = people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].count()\n",
    "total_birth_year = people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].sum()\n",
    "avg_birth_year = total_birth_year / num_birth_years\n",
    "\n",
    "total_birth_year = people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].sum()\n",
    "avg_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].mean(),name=\"Birth.Mean\")\n",
    "std_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].std(),name=\"Birth.std\")\n",
    "std_birth_year[std_birth_year.isnull()]=0\n",
    "min_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].min(),name=\"Birth.min\")\n",
    "max_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].max(),name=\"Birth.max\")\n",
    "\n",
    "avg_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].mean(),name=\"Years.Uni.avg\")\n",
    "std_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].std(),name=\"Years.Uni.std\")\n",
    "std_no_years_uni[std_no_years_uni.isnull()]=0\n",
    "min_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].min(),name=\"Years.Uni.min\")\n",
    "max_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].max(),name=\"Years.Uni.max\")\n",
    "\n",
    "\n",
    "num_successful = pd.Series(people.groupby(['Grant.Application.ID'])['Number.of.Successful.Grant.'].sum(),name=\"num_succ\")\n",
    "num_unsuccessful = pd.Series(people.groupby(['Grant.Application.ID'])['Number.of.Unsuccessful.Grant.'].sum(),name=\"num_unsucc\")\n",
    "ratio_successful = pd.Series(num_successful/(num_successful+num_unsuccessful),name=\"Ratio.Successful\")\n",
    "ratio_successful[ratio_successful.isnull()]=0\n",
    "\n",
    "# number of phds - TODO could be improved\n",
    "people[\"With.PHD.\"] = np.where(people[\"With.PHD.\"]==\"Yes\",1,0)\n",
    "num_phd  = pd.Series(people.groupby(['Grant.Application.ID'])['With.PHD.'].sum(),name=\"phd.count\") # assuming only value ever entered is yes # include\n",
    "mean_phd = pd.Series(people.groupby(['Grant.Application.ID'])['With.PHD.'].mean(),name=\"phd.mean\")# assuming only value ever entered is yes # include\n",
    "\n",
    "\n",
    "# Mysterious variables\n",
    "a__1 = pd.Series(people.groupby(['Grant.Application.ID'])['A..'].sum(),name=\"a..1.sum\") \n",
    "a_1 = pd.Series(people.groupby(['Grant.Application.ID'])['A.'].sum(),name=\"a.1.sum\") \n",
    "b_1 = pd.Series(people.groupby(['Grant.Application.ID'])['B.'].sum(),name=\"b.1.sum\")\n",
    "c_1 = pd.Series(people.groupby(['Grant.Application.ID'])['C.'].sum(),name=\"c.1.sum\")\n",
    "avg_a__1 = pd.Series(people.groupby(['Grant.Application.ID'])['A..'].mean(),name=\"a..1.avg\")  \n",
    "avg_a_1 = pd.Series(people.groupby(['Grant.Application.ID'])['A.'].mean(),name=\"a.1.avg\")  \n",
    "avg_b_1 = pd.Series(people.groupby(['Grant.Application.ID'])['B.'].mean(),name=\"b..1.avg\")  \n",
    "avg_c_1 = pd.Series(people.groupby(['Grant.Application.ID'])['C.'].mean(),name=\"c..1.avg\")  \n",
    "\n",
    "# Faculty\n",
    "fac = pd.Series(people.groupby(['Grant.Application.ID'])['Faculty.No..'].mean(),name=\"faculty\")\n",
    "\n",
    "# Department number\n",
    "dept_no = pd.Series(people.groupby(['Grant.Application.ID'])['Dept.No..'].mean(),name=\"dept_no\")\n",
    "\n",
    "# creating DF with summary statistics for each person\n",
    "people_summary = pd.DataFrame()\n",
    "ppl_groupby = people.groupby(['Person.ID.'])\n",
    "people_summary.loc[:,'Num applications'] = ppl_groupby['Grant.Application.ID'].count()\n",
    "people_summary.loc[:,'Num grant status'] = ppl_groupby['Grant.Status'].sum()\n",
    "people_summary.loc[:,'Num successful'] = ppl_groupby['Number.of.Successful.Grant.'].sum()\n",
    "people_summary.loc[:,'Num unsuccessful'] = ppl_groupby['Number.of.Unsuccessful.Grant.'].sum()\n",
    "people_summary.loc[:,'Ratio'] = people_summary.loc[:,'Num successful'] / (people_summary.loc[:,'Num unsuccessful'] + people_summary.loc[:,'Num successful'])\n",
    "people_summary.sort(columns=['Ratio'], ascending=False, inplace=True)\n",
    "\n",
    "# Number of persons per role type\n",
    "roles = people[\"Role.\"].reset_index().pivot_table(columns=\"Role.\",index=people.index,aggfunc=len,fill_value=0)\n",
    "#roles.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of people in the team\n",
    "input = pd.concat([data,num_ppl],axis=1)\n",
    "\n",
    "# Year of birth\n",
    "input = pd.concat([input,avg_birth_year],axis=1)\n",
    "input = pd.concat([input,std_birth_year],axis=1)\n",
    "input = pd.concat([input,min_birth_year],axis=1)\n",
    "input = pd.concat([input,max_birth_year],axis=1)\n",
    "\n",
    "# Years in Uni \n",
    "input = pd.concat([input,avg_no_years_uni],axis=1)\n",
    "input = pd.concat([input,std_no_years_uni],axis=1)\n",
    "input = pd.concat([input,min_no_years_uni],axis=1)\n",
    "input = pd.concat([input,max_no_years_uni],axis=1)\n",
    "\n",
    "# Application success ratio\n",
    "input = pd.concat([input,ratio_successful],axis=1)\n",
    "input = pd.concat([input,num_successful],axis=1)\n",
    "input = pd.concat([input,num_unsuccessful],axis=1)\n",
    "\n",
    "# PhDs in team\n",
    "input = pd.concat([input,num_phd],axis=1)\n",
    "input = pd.concat([input,mean_phd],axis=1)\n",
    "\n",
    "# Roles in team\n",
    "input = pd.concat([input,roles],axis=1)\n",
    "\n",
    "# Faculty\n",
    "input = pd.concat([input,fac],axis=1)\n",
    "\n",
    "# Department\n",
    "input = pd.concat([input,dept_no],axis=1)\n",
    "\n",
    "# Mysterious variables\n",
    "input = pd.concat([input,a__1],axis=1)\n",
    "input = pd.concat([input,a_1],axis=1)\n",
    "input = pd.concat([input,b_1],axis=1)\n",
    "input = pd.concat([input,c_1],axis=1)\n",
    "input = pd.concat([input,avg_a__1],axis=1)\n",
    "input = pd.concat([input,avg_a_1],axis=1)\n",
    "input = pd.concat([input,avg_b_1],axis=1)\n",
    "input = pd.concat([input,avg_c_1],axis=1)\n",
    "\n",
    "# Cleaning\n",
    "input.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add info about the first person only\n",
    "col_names = [\"ID.1\",\"Role.1\",\"Year.1\",\"Country.1\",\"Language.1\",\"Dept.1\",\"Faculty.1\",\"PHD.1\",\"Years.Uni.1\",\"Success.1\",\"Unsucces.1\",\"A..1.1\",\"A.1.1\",\"B.1.1\",\"C.1.1\"]\n",
    "person1 = people.iloc[:8708,:15]\n",
    "person1.index.name = None\n",
    "person1.columns = col_names\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "roles = list(person1[\"Role.1\"])\n",
    "le = LabelEncoder()\n",
    "le.fit(roles)\n",
    "roles_enc = le.transform(roles)\n",
    "person1[\"Role.1\"] = roles_enc\n",
    "\n",
    "country = list(person1[\"Country.1\"])\n",
    "le = LabelEncoder()\n",
    "le.fit(roles)\n",
    "country_enc = le.transform(roles)\n",
    "person1[\"Country.1\"] = country_enc\n",
    "\n",
    "language = list(person1[\"Language.1\"])\n",
    "le = LabelEncoder()\n",
    "le.fit(language)\n",
    "language_enc = le.transform(language)\n",
    "person1[\"Language.1\"] = language_enc\n",
    "\n",
    "input2 = pd.concat([input,person1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8708, 412) (8708, 427)\n",
      "(8708, 427) (8708, 427)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape,input2.shape)\n",
    "\n",
    "input.fillna(value=0,inplace=True)\n",
    "input2.fillna(value=0,inplace=True)\n",
    "\n",
    "input = input2\n",
    "\n",
    "print(input.shape,input2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_ids = pd.read_csv(\"data/testing_ids.csv\")\n",
    "testing_ids = list(testing_ids.ix[:,0])\n",
    "test = input.ix[testing_ids]\n",
    "\n",
    "all_ids = list(input.index)\n",
    "train_ids = []\n",
    "for i in all_ids:\n",
    "    if not(i in testing_ids):\n",
    "        train_ids.append(i)\n",
    "\n",
    "train = input.ix[train_ids]\n",
    "\n",
    "X_train = train.ix[:,1:]\n",
    "y_train = train.ix[:,0]\n",
    "X_test = test.ix[:,1:]\n",
    "y_test = test.ix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input.to_csv(\"data/sanitized.csv\")\n",
    "X_train.to_csv(\"data/X_train.csv\")\n",
    "X_test.to_csv(\"data/X_test.csv\")\n",
    "y_train.to_csv(\"data/y_train.csv\",header=True)\n",
    "y_test.to_csv(\"data/y_test.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "0.798290598291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\"\"\"\n",
    "rfc = RandomForestClassifier(n_jobs=-1,random_state=0)\n",
    "params={\n",
    "    \"n_estimators\":[8,10,12],\n",
    "    \"min_samples_split\":[2,4,6],\n",
    "    \"min_samples_leaf\":[1,2,4],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rfc,param_grid=params,n_jobs=-1).fit(X_train,y_train)\n",
    "\n",
    "\"\"\"\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "params={\n",
    "    \"n_estimators\":[500],\n",
    "    \"min_samples_split\":[4,5,6],\n",
    "    \"min_samples_leaf\":[2]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gbc,param_grid=params,n_jobs=-1).fit(X_train,y_train)\n",
    "\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Ratio.Successful</td>\n",
       "      <td>0.0480961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Contract_A</td>\n",
       "      <td>0.0347649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Unsucces.1</td>\n",
       "      <td>0.0250926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>num_unsucc</td>\n",
       "      <td>0.0220947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>ID.1</td>\n",
       "      <td>0.019898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>a.1.avg</td>\n",
       "      <td>0.0177171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>c..1.avg</td>\n",
       "      <td>0.017098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Success.1</td>\n",
       "      <td>0.0167131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>dept_no</td>\n",
       "      <td>0.0161277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Year_2005.0</td>\n",
       "      <td>0.0136078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name      score\n",
       "388  Ratio.Successful  0.0480961\n",
       "362        Contract_A  0.0347649\n",
       "421        Unsucces.1  0.0250926\n",
       "390        num_unsucc  0.0220947\n",
       "411              ID.1   0.019898\n",
       "408           a.1.avg  0.0177171\n",
       "410          c..1.avg   0.017098\n",
       "420         Success.1  0.0167131\n",
       "402           dept_no  0.0161277\n",
       "312       Year_2005.0  0.0136078"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([X_train.columns,cv.best_estimator_.feature_importances_]).transpose()\n",
    "df.columns=[\"name\",\"score\"]\n",
    "df.sort(columns=[\"score\"],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = cv.predict(X_test)\n",
    "y_pred_proba = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90154440154440152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred == y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_granted</th>\n",
       "      <th>predicted_granted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_granted</th>\n",
       "      <td>303</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granted</th>\n",
       "      <td>25</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             predicted_not_granted  predicted_granted\n",
       "not_granted                    303                 26\n",
       "granted                         25                164"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conmat = np.array(confusion_matrix(y_test, y_pred))\n",
    "confusion = pd.DataFrame(conmat, index=['not_granted', 'granted'],columns=['predicted_not_granted', 'predicted_granted'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92       329\n",
      "          1       0.86      0.87      0.87       189\n",
      "\n",
      "avg / total       0.90      0.90      0.90       518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print(cls_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.89435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC AUC: %.5f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
