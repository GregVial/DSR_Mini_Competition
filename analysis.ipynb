{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/unimelb_training.csv\")\n",
    "data.set_index(\"Grant.Application.ID\",drop=True,inplace=True)\n",
    "data.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.ix[:,:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Sponsor.Code</th>\n",
       "      <th>Grant.Category.Code</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>Start.date</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>...</th>\n",
       "      <th>SEO.Code.1</th>\n",
       "      <th>SEO.Percentage.1</th>\n",
       "      <th>SEO.Code.2</th>\n",
       "      <th>SEO.Percentage.2</th>\n",
       "      <th>SEO.Code.3</th>\n",
       "      <th>SEO.Percentage.3</th>\n",
       "      <th>SEO.Code.4</th>\n",
       "      <th>SEO.Percentage.4</th>\n",
       "      <th>SEO.Code.5</th>\n",
       "      <th>SEO.Percentage.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>8/11/05</td>\n",
       "      <td>280199.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>700299.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2B</td>\n",
       "      <td>10A</td>\n",
       "      <td>B</td>\n",
       "      <td>11/11/05</td>\n",
       "      <td>280103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280106.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280203.0</td>\n",
       "      <td>...</td>\n",
       "      <td>700103.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>700102.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grant.Status Sponsor.Code Grant.Category.Code  \\\n",
       "1             1          NaN                 NaN   \n",
       "2             1           2B                 10A   \n",
       "\n",
       "  Contract.Value.Band...see.note.A Start.date  RFCD.Code.1  RFCD.Percentage.1  \\\n",
       "1                               A     8/11/05     280199.0              100.0   \n",
       "2                               B    11/11/05     280103.0               30.0   \n",
       "\n",
       "   RFCD.Code.2  RFCD.Percentage.2  RFCD.Code.3        ...         SEO.Code.1  \\\n",
       "1          0.0                0.0          0.0        ...           700299.0   \n",
       "2     280106.0               30.0     280203.0        ...           700103.0   \n",
       "\n",
       "   SEO.Percentage.1  SEO.Code.2  SEO.Percentage.2  SEO.Code.3  \\\n",
       "1             100.0         0.0               0.0         0.0   \n",
       "2              50.0    700102.0              50.0         0.0   \n",
       "\n",
       "   SEO.Percentage.3  SEO.Code.4  SEO.Percentage.4  SEO.Code.5  \\\n",
       "1               0.0         0.0               0.0         0.0   \n",
       "2               0.0         0.0               0.0         0.0   \n",
       "\n",
       "   SEO.Percentage.5  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummies for Sponsor.Code\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Sponsor.Code\"],prefix=\"Sponsor\")],axis=1)\n",
    "data.drop(\"Sponsor.Code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummies for Grant.Category.Code\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Grant.Category.Code\"],prefix=\"Cat\")],axis=1)\n",
    "data.drop(\"Grant.Category.Code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>RFCD.Percentage.3</th>\n",
       "      <th>RFCD.Code.4</th>\n",
       "      <th>RFCD.Percentage.4</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_22.0</th>\n",
       "      <th>Day_23.0</th>\n",
       "      <th>Day_24.0</th>\n",
       "      <th>Day_25.0</th>\n",
       "      <th>Day_26.0</th>\n",
       "      <th>Day_27.0</th>\n",
       "      <th>Day_28.0</th>\n",
       "      <th>Day_29.0</th>\n",
       "      <th>Day_30.0</th>\n",
       "      <th>Day_31.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>280199.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>280103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280106.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280203.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>321004.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>321216.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>270602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>260500.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grant.Status Contract.Value.Band...see.note.A  RFCD.Code.1  \\\n",
       "1             1                               A      280199.0   \n",
       "2             1                               B      280103.0   \n",
       "3             1                               A      321004.0   \n",
       "4             1                               C      270602.0   \n",
       "5             0                               A      260500.0   \n",
       "\n",
       "   RFCD.Percentage.1  RFCD.Code.2  RFCD.Percentage.2  RFCD.Code.3  \\\n",
       "1              100.0          0.0                0.0          0.0   \n",
       "2               30.0     280106.0               30.0     280203.0   \n",
       "3               60.0     321216.0               40.0          0.0   \n",
       "4               50.0     320602.0               50.0          0.0   \n",
       "5               34.0     280000.0               33.0     290000.0   \n",
       "\n",
       "   RFCD.Percentage.3  RFCD.Code.4  RFCD.Percentage.4    ...     Day_22.0  \\\n",
       "1                0.0          0.0                0.0    ...          0.0   \n",
       "2               40.0          0.0                0.0    ...          0.0   \n",
       "3                0.0          0.0                0.0    ...          0.0   \n",
       "4                0.0          0.0                0.0    ...          0.0   \n",
       "5               33.0          0.0                0.0    ...          0.0   \n",
       "\n",
       "   Day_23.0  Day_24.0  Day_25.0  Day_26.0  Day_27.0  Day_28.0  Day_29.0  \\\n",
       "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "5       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   Day_30.0  Day_31.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       0.0       0.0  \n",
       "4       0.0       0.0  \n",
       "5       0.0       0.0  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with date\n",
    "\n",
    "a = pd.to_datetime(data[\"Start.date\"])\n",
    "year = pd.Series([date.year for date in a],name=\"year\")\n",
    "month = pd.Series([date.month for date in a],name=\"month\")\n",
    "day = pd.Series([date.day for date in a],name=\"day\")\n",
    "data[\"Start.year\"] = year\n",
    "data[\"Start.month\"] = month\n",
    "data[\"Start.day\"] = day\n",
    "\n",
    "# one hot encoding\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Start.year\"],prefix=\"Year\")],axis=1)\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Start.month\"],prefix=\"Month\")],axis=1)\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Start.day\"],prefix=\"Day\")],axis=1)\n",
    "\n",
    "data.drop([\"Start.date\"],axis=1,inplace=True)\n",
    "data.drop([\"Start.year\"],axis=1,inplace=True)\n",
    "data.drop([\"Start.month\"],axis=1,inplace=True)\n",
    "data.drop([\"Start.day\"],axis=1,inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummies for Contract.Val\n",
    "data = pd.concat([data,pd.get_dummies(data[\"Contract.Value.Band...see.note.A\"],prefix=\"Contract\")],axis=1)\n",
    "data.drop(\"Contract.Value.Band...see.note.A\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Int64Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cf0a749fa61d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mRFCD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRFCD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RFCD.Code\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mpiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRFCD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"RFCD.Code\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRFCD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mpiv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\tools\\pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues_passed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3044\u001b[0m         \"\"\"\n\u001b[1;32m   3045\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_labels_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2095\u001b[0m                                  'backfill or nearest reindexing')\n\u001b[1;32m   2096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_indexer (pandas\\index.c:5927)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.lookup (pandas\\hashtable.c:13317)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unhashable type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Int64Index'"
     ]
    }
   ],
   "source": [
    "# Create dummies for RFCD\n",
    "sub1 = pd.DataFrame(data.ix[:,1:3])\n",
    "sub1.rename(columns={\"RFCD.Code.1\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.1\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub2 = pd.DataFrame(data.ix[:,3:5])\n",
    "sub2.rename(columns={\"RFCD.Code.2\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.2\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub3 = pd.DataFrame(data.ix[:,5:7])\n",
    "sub3.rename(columns={\"RFCD.Code.3\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.3\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub4 = pd.DataFrame(data.ix[:,7:9])\n",
    "sub4.rename(columns={\"RFCD.Code.4\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.4\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "sub5 = pd.DataFrame(data.ix[:,9:11])\n",
    "sub5.rename(columns={\"RFCD.Code.5\":\"RFCD.Code\",\n",
    "                     \"RFCD.Percentage.5\":\"RFCD.Percentage\"},inplace=True)\n",
    "\n",
    "RFCD = sub1.append(sub2,ignore_index=False)\n",
    "RFCD = RFCD.append(sub3,ignore_index=False)\n",
    "RFCD = RFCD.append(sub4,ignore_index=False)\n",
    "RFCD = RFCD.append(sub4,ignore_index=False)\n",
    "\n",
    "RFCD[RFCD[\"RFCD.Code\"].isnull()]=0\n",
    "\n",
    "piv = pd.pivot_table(RFCD,columns=\"RFCD.Code\",index=RFCD.index,fill_value=0,dropna=False)\n",
    "piv[piv.isnull()]=0\n",
    "piv.index.name=None\n",
    "\n",
    "#data = pd.concat([data,piv],axis=1)\n",
    "data.drop([\"RFCD.Code.1\",\"RFCD.Percentage.1\",\n",
    "           \"RFCD.Code.2\",\"RFCD.Percentage.2\",\n",
    "           \"RFCD.Code.3\",\"RFCD.Percentage.3\",\n",
    "           \"RFCD.Code.4\",\"RFCD.Percentage.4\",\n",
    "           \"RFCD.Code.5\",\"RFCD.Percentage.5\",],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SEO.Code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4066)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3930)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12408)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SEO.Code'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-55ee1e614cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mSEO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSEO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mSEO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSEO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SEO.Code\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mpiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"SEO.Code\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRFCD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4066)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3930)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12408)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SEO.Code'"
     ]
    }
   ],
   "source": [
    "# Create dummies for SEO\n",
    "sub1 = pd.DataFrame(data.ix[:,1:3])\n",
    "sub1.rename(columns={\"SEO.Code.1\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.1\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub2 = pd.DataFrame(data.ix[:,3:5])\n",
    "sub2.rename(columns={\"SEO.Code.2\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.2\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub3 = pd.DataFrame(data.ix[:,5:7])\n",
    "sub3.rename(columns={\"SEO.Code.3\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.3\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub4 = pd.DataFrame(data.ix[:,7:9])\n",
    "sub4.rename(columns={\"SEO.Code.4\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.4\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "sub5 = pd.DataFrame(data.ix[:,9:11])\n",
    "sub5.rename(columns={\"SEO.Code.5\":\"SEO.Code\",\n",
    "                     \"SEO.Percentage.5\":\"SEO.Percentage\"},inplace=True)\n",
    "\n",
    "SEO = sub1.append(sub2,ignore_index=False)\n",
    "SEO = SEO.append(sub3,ignore_index=False)\n",
    "SEO = SEO.append(sub4,ignore_index=False)\n",
    "SEO = SEO.append(sub4,ignore_index=False)\n",
    "\n",
    "SEO[SEO[\"SEO.Code\"].isnull()]=0\n",
    "\n",
    "piv = pd.pivot_table(SEO,columns=\"SEO.Code\",index=RFCD.index,fill_value=0,dropna=False)\n",
    "piv[piv.isnull()]=0\n",
    "piv.index.name=None\n",
    "\n",
    "#data = pd.concat([data,piv],axis=1)\n",
    "data.drop([\"SEO.Code.1\",\"SEO.Percentage.1\",\n",
    "           \"SEO.Code.2\",\"SEO.Percentage.2\",\n",
    "           \"SEO.Code.3\",\"SEO.Percentage.3\",\n",
    "           \"SEO.Code.4\",\"SEO.Percentage.4\",\n",
    "           \"SEO.Code.5\",\"SEO.Percentage.5\",],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:112: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Int64Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a13185760b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[1;31m# Number of persons per role type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mroles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpeople\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Role.\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Role.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpeople\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[1;31m#roles.fillna(value=0,inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\tools\\pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues_passed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3044\u001b[0m         \"\"\"\n\u001b[1;32m   3045\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_labels_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2095\u001b[0m                                  'backfill or nearest reindexing')\n\u001b[1;32m   2096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_indexer (pandas\\index.c:5927)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.lookup (pandas\\hashtable.c:13317)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unhashable type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Int64Index'"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "raw = pd.read_csv(\"data/unimelb_training.csv\")\n",
    "\n",
    "people = pd.DataFrame()\n",
    "time_at_uni = pd.DataFrame()\n",
    "for col in raw.columns:\n",
    "    col_list = list(raw.columns) # list so I can use index later\n",
    "\n",
    "    if col[:10] == 'Person.ID.':\n",
    "        col_start = col_list.index(col)\n",
    "        col_end = col_start + 15 # hard coded\n",
    "        person = raw.iloc[:,col_start:col_end]\n",
    "        \n",
    "       \n",
    "        # including our ID and status\n",
    "        person.loc[:,'Grant.Application.ID'] = raw.loc[:,'Grant.Application.ID']\n",
    "        person.loc[:,'Grant.Status'] = raw.loc[:,'Grant.Status']\n",
    "\n",
    "        col_names = list(person.columns)\n",
    "        col_names = [col.strip('0123456789') for col in col_names] # removes all numbers\n",
    "        person.columns = col_names\n",
    "        #print(len(person))\n",
    "        \n",
    "        # Dealing with missing IDs\n",
    "        id_ = person.loc[:,\"Person.ID.\"]\n",
    "        id_missing = [np.isnan(i) for i in id_]\n",
    "        #print(id_missing[50:60])\n",
    "        role = person.loc[:,\"Role.\"]\n",
    "        #print(role[50:60])\n",
    "        role_not_missing = [not pd.isnull(r) for r in role]\n",
    "        #print(role_not_missing[50:60])\n",
    "        no_id = [(i&r) for (i,r) in zip(id_missing,role_not_missing)]\n",
    "        #print(no_id[50:60])\n",
    "        person.loc[:,\"Person.ID.\"] = np.where(no_id,0,person.loc[:,\"Person.ID.\"])\n",
    "        #print(person.loc[50:60,\"Person.ID.\"])\n",
    "\n",
    "        # dealing with number of years at uni\n",
    "        original = person.loc[:,'No..of.Years.in.Uni.at.Time.of.Grant.'].astype(str)\n",
    "        transformed = [0 for _ in range(original.size)]\n",
    "        transformed = np.where(original==\">=0 to 5\",2.5,transformed)\n",
    "        transformed = np.where(original==\">5 to 10\",7.5,transformed)\n",
    "        transformed = np.where(original==\">10 to 15\",12.5,transformed)\n",
    "        transformed = np.where(original==\"more than 15\",20,transformed)\n",
    "        transformed = pd.DataFrame(transformed)\n",
    "\n",
    "        person[\"No..of.Years.in.Uni.at.Time.of.Grant.\"] = transformed\n",
    "        #person = pd.concat([person, transformed], axis=1)\n",
    "        people = people.append(person, ignore_index=True)\n",
    "        #print(people.loc[:,\"Person.ID.\"])\n",
    "\n",
    "# summaries for team\n",
    "#num_ppl = len(people) / len(person) # should be 15!\n",
    "people.index = people.loc[:,'Grant.Application.ID']\n",
    "num_ppl = pd.Series(people.groupby(['Grant.Application.ID'])['Person.ID.'].count(),name=\"Person.ID.\") # include\n",
    "#num_ppl = np.where(num_ppl==0,1,num_ppl)\n",
    "#print(num_ppl)\n",
    "\n",
    "num_birth_years = people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].count()\n",
    "total_birth_year = people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].sum()\n",
    "avg_birth_year = total_birth_year / num_birth_years\n",
    "\n",
    "total_birth_year = people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].sum()\n",
    "avg_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].mean(),name=\"Birth.Mean\")\n",
    "std_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].std(),name=\"Birth.std\")\n",
    "std_birth_year[std_birth_year.isnull()]=0\n",
    "min_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].min(),name=\"Birth.min\")\n",
    "max_birth_year = pd.Series(people.groupby(['Grant.Application.ID'])['Year.of.Birth.'].max(),name=\"Birth.max\")\n",
    "\n",
    "avg_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].mean(),name=\"Years.Uni.avg\")\n",
    "std_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].std(),name=\"Years.Uni.std\")\n",
    "std_no_years_uni[std_no_years_uni.isnull()]=0\n",
    "min_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].min(),name=\"Years.Uni.min\")\n",
    "max_no_years_uni = pd.Series(people.groupby(['Grant.Application.ID'])['No..of.Years.in.Uni.at.Time.of.Grant.'].max(),name=\"Years.Uni.max\")\n",
    "\n",
    "\n",
    "num_successful = pd.Series(people.groupby(['Grant.Application.ID'])['Number.of.Successful.Grant.'].sum(),name=\"num_succ\")\n",
    "num_unsuccessful = pd.Series(people.groupby(['Grant.Application.ID'])['Number.of.Unsuccessful.Grant.'].sum(),name=\"num_unsucc\")\n",
    "ratio_successful = pd.Series(num_successful/(num_successful+num_unsuccessful),name=\"Ratio.Successful\")\n",
    "ratio_successful[ratio_successful.isnull()]=0\n",
    "\n",
    "# number of phds - TODO could be improved\n",
    "people[\"With.PHD.\"] = np.where(people[\"With.PHD.\"]==\"Yes\",1,0)\n",
    "num_phd  = pd.Series(people.groupby(['Grant.Application.ID'])['With.PHD.'].sum(),name=\"phd.count\") # assuming only value ever entered is yes # include\n",
    "mean_phd = pd.Series(people.groupby(['Grant.Application.ID'])['With.PHD.'].mean(),name=\"phd.mean\")# assuming only value ever entered is yes # include\n",
    "\n",
    "\n",
    "# Mysterious variables\n",
    "a__1 = pd.Series(people.groupby(['Grant.Application.ID'])['A..'].sum(),name=\"a..1.sum\") \n",
    "a_1 = pd.Series(people.groupby(['Grant.Application.ID'])['A.'].sum(),name=\"a.1.sum\") \n",
    "b_1 = pd.Series(people.groupby(['Grant.Application.ID'])['B.'].sum(),name=\"b.1.sum\")\n",
    "c_1 = pd.Series(people.groupby(['Grant.Application.ID'])['C.'].sum(),name=\"c.1.sum\")\n",
    "avg_a__1 = pd.Series(people.groupby(['Grant.Application.ID'])['A..'].mean(),name=\"a..1.avg\")  \n",
    "avg_a_1 = pd.Series(people.groupby(['Grant.Application.ID'])['A.'].mean(),name=\"a.1.avg\")  \n",
    "avg_b_1 = pd.Series(people.groupby(['Grant.Application.ID'])['B.'].mean(),name=\"b..1.avg\")  \n",
    "avg_c_1 = pd.Series(people.groupby(['Grant.Application.ID'])['C.'].mean(),name=\"c..1.avg\")  \n",
    "\n",
    "# Faculty\n",
    "fac = pd.Series(people.groupby(['Grant.Application.ID'])['Faculty.No..'].mean(),name=\"faculty\")\n",
    "\n",
    "# Department number\n",
    "dept_no = pd.Series(people.groupby(['Grant.Application.ID'])['Dept.No..'].mean(),name=\"dept_no\")\n",
    "\n",
    "# creating DF with summary statistics for each person\n",
    "people_summary = pd.DataFrame()\n",
    "ppl_groupby = people.groupby(['Person.ID.'])\n",
    "people_summary.loc[:,'Num applications'] = ppl_groupby['Grant.Application.ID'].count()\n",
    "people_summary.loc[:,'Num grant status'] = ppl_groupby['Grant.Status'].sum()\n",
    "people_summary.loc[:,'Num successful'] = ppl_groupby['Number.of.Successful.Grant.'].sum()\n",
    "people_summary.loc[:,'Num unsuccessful'] = ppl_groupby['Number.of.Unsuccessful.Grant.'].sum()\n",
    "people_summary.loc[:,'Ratio'] = people_summary.loc[:,'Num successful'] / (people_summary.loc[:,'Num unsuccessful'] + people_summary.loc[:,'Num successful'])\n",
    "people_summary.sort(columns=['Ratio'], ascending=False, inplace=True)\n",
    "\n",
    "# Number of persons per role type\n",
    "roles = people[\"Role.\"].reset_index().pivot_table(columns=\"Role.\",index=people.index,aggfunc=len,fill_value=0)\n",
    "#roles.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of people in the team\n",
    "input = pd.concat([data,num_ppl],axis=1)\n",
    "\n",
    "# Year of birth\n",
    "input = pd.concat([input,avg_birth_year],axis=1)\n",
    "input = pd.concat([input,std_birth_year],axis=1)\n",
    "input = pd.concat([input,min_birth_year],axis=1)\n",
    "input = pd.concat([input,max_birth_year],axis=1)\n",
    "\n",
    "# Years in Uni \n",
    "input = pd.concat([input,avg_no_years_uni],axis=1)\n",
    "input = pd.concat([input,std_no_years_uni],axis=1)\n",
    "input = pd.concat([input,min_no_years_uni],axis=1)\n",
    "input = pd.concat([input,max_no_years_uni],axis=1)\n",
    "\n",
    "# Application success ratio\n",
    "input = pd.concat([input,ratio_successful],axis=1)\n",
    "input = pd.concat([input,num_successful],axis=1)\n",
    "input = pd.concat([input,num_unsuccessful],axis=1)\n",
    "\n",
    "# PhDs in team\n",
    "input = pd.concat([input,num_phd],axis=1)\n",
    "input = pd.concat([input,mean_phd],axis=1)\n",
    "\n",
    "# Roles in team\n",
    "input = pd.concat([input,roles],axis=1)\n",
    "\n",
    "# Faculty\n",
    "input = pd.concat([input,fac],axis=1)\n",
    "\n",
    "# Department\n",
    "input = pd.concat([input,dept_no],axis=1)\n",
    "\n",
    "# Mysterious variables\n",
    "input = pd.concat([input,a__1],axis=1)\n",
    "input = pd.concat([input,a_1],axis=1)\n",
    "input = pd.concat([input,b_1],axis=1)\n",
    "input = pd.concat([input,c_1],axis=1)\n",
    "input = pd.concat([input,avg_a__1],axis=1)\n",
    "input = pd.concat([input,avg_a_1],axis=1)\n",
    "input = pd.concat([input,avg_b_1],axis=1)\n",
    "input = pd.concat([input,avg_c_1],axis=1)\n",
    "\n",
    "# Cleaning\n",
    "input.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input.to_csv(\"data/before_replace.csv\")\n",
    "\n",
    "input.fillna(value=0,inplace=True)\n",
    "input.to_csv(\"data/after_replace.csv\")\n",
    "\n",
    "testing_ids = pd.read_csv(\"data/testing_ids.csv\")\n",
    "testing_ids = list(testing_ids.ix[:,0])\n",
    "test = input.ix[testing_ids]\n",
    "\n",
    "all_ids = list(input.index)\n",
    "train_ids = []\n",
    "for i in all_ids:\n",
    "    if not(i in testing_ids):\n",
    "        train_ids.append(i)\n",
    "\n",
    "train = input.ix[train_ids]\n",
    "\n",
    "X_train = train.ix[:,1:]\n",
    "y_train = train.ix[:,0]\n",
    "X_test = test.ix[:,1:]\n",
    "y_test = test.ix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input.to_csv(\"data/sanitized.csv\")\n",
    "X_train.to_csv(\"data/X_train.csv\")\n",
    "X_test.to_csv(\"data/X_test.csv\")\n",
    "y_train.to_csv(\"data/y_train.csv\",header=True)\n",
    "y_test.to_csv(\"data/y_test.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=131078)\n",
    "\n",
    "\"\"\"\n",
    "rfc = RandomForestClassifier(n_jobs=-1,random_state=0)\n",
    "params={\n",
    "    \"n_estimators\":[8,10,12],\n",
    "    \"min_samples_split\":[2,4,6],\n",
    "    \"min_samples_leaf\":[1,2,4],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rfc,param_grid=params,n_jobs=-1).fit(X_train,y_train)\n",
    "\n",
    "\"\"\"\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "params={\n",
    "    \"n_estimators\":[500],\n",
    "    \"min_samples_split\":[6],\n",
    "    \"min_samples_leaf\":[2],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gbc,param_grid=params,n_jobs=-1).fit(X_train,y_train)\n",
    "\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([X.columns,cv.best_estimator_.feature_importances_]).transpose()\n",
    "df.columns=[\"name\",\"score\"]\n",
    "df.sort(columns=[\"score\"],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred =cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = np.mean(y_pred == y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conmat = np.array(confusion_matrix(y_test, y_pred))\n",
    "confusion = pd.DataFrame(conmat, index=['not_granted', 'granted'],columns=['predicted_not_granted', 'predicted_granted'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print(cls_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC: %.4f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,n in enumerate(input):\n",
    "    print(i,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
